{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables for covariates\n",
    "On this code, I select varibles from datasets downloaded from Gloogle Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ACS 1-year\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Make table with all ACS-1 year\n",
    "#### list all available files and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACS_2010.csv',\n",
       " 'ACS_2011.csv',\n",
       " 'ACS_2012.csv',\n",
       " 'ACS_2013.csv',\n",
       " 'ACS_2014.csv',\n",
       " 'ACS_2015.csv',\n",
       " 'ACS_2016.csv',\n",
       " 'ACS_2017.csv',\n",
       " 'ACS_2018.csv']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all ACS files downloaded\n",
    "f = [file[-12:] for file in glob.glob(\"../input2/ACS_*\")]\n",
    "f.sort()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input2/ACS_2010.csv',\n",
       " '../input2/ACS_2011.csv',\n",
       " '../input2/ACS_2012.csv',\n",
       " '../input2/ACS_2013.csv',\n",
       " '../input2/ACS_2014.csv',\n",
       " '../input2/ACS_2015.csv',\n",
       " '../input2/ACS_2016.csv',\n",
       " '../input2/ACS_2017.csv',\n",
       " '../input2/ACS_2018.csv']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files = glob.glob(\"../input2/ACS_*\")\n",
    "all_files.sort()\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check missing variables accross files\n",
    "\n",
    "The columns (variables) from imported files are not the same, as seen bellow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>n. variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACS_2010</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACS_2011</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACS_2012</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACS_2013</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACS_2014</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACS_2015</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACS_2016</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACS_2017</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACS_2018</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       file  n. variables\n",
       "0  ACS_2010           247\n",
       "1  ACS_2011           252\n",
       "2  ACS_2012           252\n",
       "3  ACS_2013           252\n",
       "4  ACS_2014           252\n",
       "5  ACS_2015           246\n",
       "6  ACS_2016           252\n",
       "7  ACS_2017           252\n",
       "8  ACS_2018           252"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of columns for each file\n",
    "dic = dict()\n",
    "for f in all_files:\n",
    "    dic.update({f[-12:-4]:len(pd.read_csv(f, index_col=0,nrows=1).columns)})\n",
    "df = pd.DataFrame.from_dict(dic, orient='index').reset_index()\n",
    "df.columns = ['file','n. variables']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate variables left out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with columns for each df\n",
    "cols = [list(pd.read_csv(f, index_col=0,nrows=1).columns) for f in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([247, 252, 252, 252, 252, 246, 252, 252, 252],)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lengths do not match\n",
    "[len(col) for col in cols], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../input2/ACS_2018.csv'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'armed_forces',\n",
       "  'civilian_labor_force',\n",
       "  'employed_pop',\n",
       "  'not_in_labor_force',\n",
       "  'pop_16_over',\n",
       "  'pop_in_labor_force',\n",
       "  'unemployed_pop'},\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " set(),\n",
       " {'pop_15_and_over',\n",
       "  'pop_divorced',\n",
       "  'pop_never_married',\n",
       "  'pop_now_married',\n",
       "  'pop_separated',\n",
       "  'pop_widowed'},\n",
       " set(),\n",
       " set(),\n",
       " set()]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check variables left out\n",
    "# I will use for reference last df (2018)\n",
    "reference_col = set(cols[-1])\n",
    "# variables missing (relative to last dataframe)\n",
    "[reference_col - set(c) for c in cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: data for 2010 and 2015 have missing columns. As I am not using 2010, for now, I will keep employment and unemployment, and drop variables missing on 2015 from concatenated final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input2/ACS_2011.csv',\n",
       " '../input2/ACS_2012.csv',\n",
       " '../input2/ACS_2013.csv',\n",
       " '../input2/ACS_2014.csv',\n",
       " '../input2/ACS_2015.csv',\n",
       " '../input2/ACS_2016.csv',\n",
       " '../input2/ACS_2017.csv',\n",
       " '../input2/ACS_2018.csv']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove 2010 form files list\n",
    "all_files.remove('../input2/ACS_2010.csv')\n",
    "all_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concatenate files\n",
    "I will concatenate files for 2011 to 2018, and drop columns not available for 2015. I will also drop geoids that are not FIPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>nonfamily_households</th>\n",
       "      <th>family_households</th>\n",
       "      <th>median_year_structure_built</th>\n",
       "      <th>rent_burden_not_computed</th>\n",
       "      <th>rent_over_50_percent</th>\n",
       "      <th>rent_40_to_50_percent</th>\n",
       "      <th>rent_35_to_40_percent</th>\n",
       "      <th>rent_30_to_35_percent</th>\n",
       "      <th>rent_25_to_30_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>speak_only_english_at_home</th>\n",
       "      <th>speak_spanish_at_home</th>\n",
       "      <th>speak_spanish_at_home_low_english</th>\n",
       "      <th>pop_15_and_over</th>\n",
       "      <th>pop_never_married</th>\n",
       "      <th>pop_now_married</th>\n",
       "      <th>pop_separated</th>\n",
       "      <th>pop_widowed</th>\n",
       "      <th>pop_divorced</th>\n",
       "      <th>do_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26055</td>\n",
       "      <td>11109.0</td>\n",
       "      <td>22290.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2346.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>1082.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73364.0</td>\n",
       "      <td>19754.0</td>\n",
       "      <td>38686.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>3608.0</td>\n",
       "      <td>10332.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37035</td>\n",
       "      <td>16362.0</td>\n",
       "      <td>40016.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>1425.0</td>\n",
       "      <td>3519.0</td>\n",
       "      <td>753.0</td>\n",
       "      <td>1330.0</td>\n",
       "      <td>1583.0</td>\n",
       "      <td>1184.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124575.0</td>\n",
       "      <td>35123.0</td>\n",
       "      <td>64074.0</td>\n",
       "      <td>2925.0</td>\n",
       "      <td>8574.0</td>\n",
       "      <td>13266.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40131</td>\n",
       "      <td>7143.0</td>\n",
       "      <td>26362.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>954.0</td>\n",
       "      <td>497.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>945.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69611.0</td>\n",
       "      <td>12467.0</td>\n",
       "      <td>45910.0</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>3511.0</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41071</td>\n",
       "      <td>9191.0</td>\n",
       "      <td>23487.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>2363.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>765.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80186.0</td>\n",
       "      <td>24263.0</td>\n",
       "      <td>40392.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>4641.0</td>\n",
       "      <td>7684.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36091</td>\n",
       "      <td>32017.0</td>\n",
       "      <td>58213.0</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>4705.0</td>\n",
       "      <td>1651.0</td>\n",
       "      <td>2669.0</td>\n",
       "      <td>1543.0</td>\n",
       "      <td>2463.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181368.0</td>\n",
       "      <td>49757.0</td>\n",
       "      <td>100158.0</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>16547.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>51199</td>\n",
       "      <td>8233.0</td>\n",
       "      <td>16763.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>358.0</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>844.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>41003</td>\n",
       "      <td>14720.0</td>\n",
       "      <td>20800.0</td>\n",
       "      <td>1978.0</td>\n",
       "      <td>798.0</td>\n",
       "      <td>5402.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>685.0</td>\n",
       "      <td>940.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>4003</td>\n",
       "      <td>18646.0</td>\n",
       "      <td>31105.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1151.0</td>\n",
       "      <td>2766.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>989.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1345.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>53029</td>\n",
       "      <td>10416.0</td>\n",
       "      <td>24156.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>533.0</td>\n",
       "      <td>1670.0</td>\n",
       "      <td>929.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>51510</td>\n",
       "      <td>36260.0</td>\n",
       "      <td>35480.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>824.0</td>\n",
       "      <td>7244.0</td>\n",
       "      <td>3083.0</td>\n",
       "      <td>2842.0</td>\n",
       "      <td>3862.0</td>\n",
       "      <td>4135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6639 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     geo_id  nonfamily_households  family_households  \\\n",
       "0     26055               11109.0            22290.0   \n",
       "1     37035               16362.0            40016.0   \n",
       "2     40131                7143.0            26362.0   \n",
       "3     41071                9191.0            23487.0   \n",
       "4     36091               32017.0            58213.0   \n",
       "..      ...                   ...                ...   \n",
       "833   51199                8233.0            16763.0   \n",
       "834   41003               14720.0            20800.0   \n",
       "835    4003               18646.0            31105.0   \n",
       "836   53029               10416.0            24156.0   \n",
       "837   51510               36260.0            35480.0   \n",
       "\n",
       "     median_year_structure_built  rent_burden_not_computed  \\\n",
       "0                         1985.0                     151.0   \n",
       "1                         1982.0                    1425.0   \n",
       "2                         1988.0                     600.0   \n",
       "3                         1984.0                     723.0   \n",
       "4                         1979.0                     538.0   \n",
       "..                           ...                       ...   \n",
       "833                       1989.0                     280.0   \n",
       "834                       1978.0                     798.0   \n",
       "835                       1985.0                    1151.0   \n",
       "836                       1985.0                     533.0   \n",
       "837                       1972.0                     824.0   \n",
       "\n",
       "     rent_over_50_percent  rent_40_to_50_percent  rent_35_to_40_percent  \\\n",
       "0                  2346.0                  597.0                  409.0   \n",
       "1                  3519.0                  753.0                 1330.0   \n",
       "2                   954.0                  497.0                  436.0   \n",
       "3                  2363.0                  669.0                  924.0   \n",
       "4                  4705.0                 1651.0                 2669.0   \n",
       "..                    ...                    ...                    ...   \n",
       "833                 983.0                  677.0                  358.0   \n",
       "834                5402.0                  826.0                  685.0   \n",
       "835                2766.0                 1024.0                  989.0   \n",
       "836                1670.0                  929.0                  619.0   \n",
       "837                7244.0                 3083.0                 2842.0   \n",
       "\n",
       "     rent_30_to_35_percent  rent_25_to_30_percent  ...  \\\n",
       "0                    702.0                 1082.0  ...   \n",
       "1                   1583.0                 1184.0  ...   \n",
       "2                    676.0                  945.0  ...   \n",
       "3                    765.0                 1494.0  ...   \n",
       "4                   1543.0                 2463.0  ...   \n",
       "..                     ...                    ...  ...   \n",
       "833                 1192.0                  844.0  ...   \n",
       "834                  940.0                 1137.0  ...   \n",
       "835                 1329.0                 1345.0  ...   \n",
       "836                  955.0                  888.0  ...   \n",
       "837                 3862.0                 4135.0  ...   \n",
       "\n",
       "     speak_only_english_at_home  speak_spanish_at_home  \\\n",
       "0                           NaN                    NaN   \n",
       "1                           NaN                    NaN   \n",
       "2                           NaN                    NaN   \n",
       "3                           NaN                    NaN   \n",
       "4                           NaN                    NaN   \n",
       "..                          ...                    ...   \n",
       "833                         NaN                    NaN   \n",
       "834                         NaN                    NaN   \n",
       "835                         NaN                    NaN   \n",
       "836                         NaN                    NaN   \n",
       "837                         NaN                    NaN   \n",
       "\n",
       "     speak_spanish_at_home_low_english  pop_15_and_over  pop_never_married  \\\n",
       "0                                  NaN          73364.0            19754.0   \n",
       "1                                  NaN         124575.0            35123.0   \n",
       "2                                  NaN          69611.0            12467.0   \n",
       "3                                  NaN          80186.0            24263.0   \n",
       "4                                  NaN         181368.0            49757.0   \n",
       "..                                 ...              ...                ...   \n",
       "833                                NaN              NaN                NaN   \n",
       "834                                NaN              NaN                NaN   \n",
       "835                                NaN              NaN                NaN   \n",
       "836                                NaN              NaN                NaN   \n",
       "837                                NaN              NaN                NaN   \n",
       "\n",
       "     pop_now_married  pop_separated  pop_widowed  pop_divorced  do_date  \n",
       "0            38686.0          723.0       3608.0       10332.0     2011  \n",
       "1            64074.0         2925.0       8574.0       13266.0     2011  \n",
       "2            45910.0         1571.0       3511.0        6146.0     2011  \n",
       "3            40392.0         2172.0       4641.0        7684.0     2011  \n",
       "4           100158.0         4914.0       9222.0       16547.0     2011  \n",
       "..               ...            ...          ...           ...      ...  \n",
       "833              NaN            NaN          NaN           NaN     2018  \n",
       "834              NaN            NaN          NaN           NaN     2018  \n",
       "835              NaN            NaN          NaN           NaN     2018  \n",
       "836              NaN            NaN          NaN           NaN     2018  \n",
       "837              NaN            NaN          NaN           NaN     2018  \n",
       "\n",
       "[6639 rows x 252 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate all files\n",
    "df = pd.concat((pd.read_csv(f, index_col=0) for f in all_files))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save local\n",
    "df.to_csv('../output/tbl_ACS.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Choose variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow I list all the variables available. I have edited the output form `df.columns` to manually organize subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy/paste the results from df.columns to manually organize subjects, as bellow\n",
    "\n",
    "variables = ['geo_id',\n",
    " \n",
    " # population age/sex\n",
    " 'total_pop',\n",
    " 'median_age',\n",
    " 'not_us_citizen_pop',\n",
    " \n",
    " 'population_1_year_and_over',\n",
    " 'population_3_years_over',\n",
    " 'pop_5_years_over',\n",
    " 'pop_15_and_over',\n",
    " 'pop_25_years_over',\n",
    " 'pop_25_64',    # labour age\n",
    "\n",
    " 'male_pop',\n",
    " 'male_under_5',\n",
    " 'male_5_to_9',\n",
    " 'male_10_to_14',\n",
    " 'male_15_to_17',\n",
    " 'male_18_to_19',\n",
    " 'male_20',\n",
    " 'male_21',\n",
    " 'male_22_to_24',\n",
    " 'male_25_to_29',\n",
    " 'male_30_to_34',\n",
    " 'male_35_to_39',\n",
    " 'male_40_to_44',\n",
    " 'male_45_to_49',\n",
    " 'male_50_to_54',\n",
    " 'male_55_to_59',\n",
    " 'male_60_61',\n",
    " 'male_62_64',\n",
    " 'male_65_to_66',\n",
    " 'male_67_to_69',\n",
    " 'male_70_to_74',\n",
    " 'male_75_to_79',\n",
    " 'male_80_to_84',\n",
    " 'male_85_and_over',\n",
    " 'male_45_to_64',   # on highest income bin\n",
    " \n",
    " 'female_pop',\n",
    " 'female_under_5',\n",
    " 'female_5_to_9',\n",
    " 'female_10_to_14',\n",
    " 'female_15_to_17',\n",
    " 'female_18_to_19',\n",
    " 'female_20',\n",
    " 'female_21',\n",
    " 'female_22_to_24',\n",
    " 'female_25_to_29',\n",
    " 'female_30_to_34',\n",
    " 'female_35_to_39',\n",
    " 'female_40_to_44',\n",
    " 'female_45_to_49',\n",
    " 'female_50_to_54',\n",
    " 'female_55_to_59',\n",
    " 'female_60_to_61',\n",
    " 'female_62_to_64',\n",
    " 'female_65_to_66',\n",
    " 'female_67_to_69',\n",
    " 'female_70_to_74',\n",
    " 'female_75_to_79',\n",
    " 'female_80_to_84',\n",
    " 'female_85_and_over',\n",
    " \n",
    " 'children',\n",
    " \n",
    " # household composition\n",
    " 'households',\n",
    "             \n",
    " 'nonfamily_households',\n",
    " 'family_households',\n",
    " 'married_households',\n",
    "            \n",
    " 'female_female_households',\n",
    " 'male_male_households',\n",
    "             \n",
    " 'children_in_single_female_hh',\n",
    "             \n",
    " 'families_with_young_children',\n",
    " 'one_parent_families_with_young_children',\n",
    " 'two_parent_families_with_young_children',\n",
    "             \n",
    " 'two_parents_father_in_labor_force_families_with_young_children',\n",
    " 'two_parents_mother_in_labor_force_families_with_young_children',\n",
    " 'two_parents_in_labor_force_families_with_young_children',\n",
    " 'two_parents_not_in_labor_force_families_with_young_children',\n",
    " \n",
    " 'father_in_labor_force_one_parent_families_with_young_children',\n",
    " 'father_one_parent_families_with_young_children',\n",
    "\n",
    " # income\n",
    " 'median_income',\n",
    " 'income_per_capita',\n",
    " 'households_retirement_income',\n",
    " 'income_less_10000',\n",
    " 'income_10000_14999',\n",
    " 'income_15000_19999',\n",
    " 'income_20000_24999',\n",
    " 'income_25000_29999',\n",
    " 'income_30000_34999',\n",
    " 'income_35000_39999',\n",
    " 'income_40000_44999',\n",
    " 'income_45000_49999',\n",
    " 'income_50000_59999',\n",
    " 'income_60000_74999',\n",
    " 'income_75000_99999',\n",
    " 'income_100000_124999',\n",
    " 'income_125000_149999',\n",
    " 'income_150000_199999',\n",
    " 'income_200000_or_more',\n",
    "   \n",
    " # schooling \n",
    " 'in_grades_1_to_4',\n",
    " 'in_grades_5_to_8',\n",
    " 'in_grades_9_to_12',\n",
    " 'in_school',\n",
    " 'in_undergrad_college',\n",
    " \n",
    " 'less_than_high_school_graduate',\n",
    " 'high_school_diploma',\n",
    " 'some_college_and_associates_degree',\n",
    " 'associates_degree',\n",
    " 'bachelors_degree',\n",
    " 'masters_degree',\n",
    " 'graduate_professional_degree',\n",
    "\n",
    " 'bachelors_degree_2',\n",
    " 'bachelors_degree_or_higher_25_64',\n",
    " 'high_school_including_ged',\n",
    " \n",
    " 'less_one_year_college', # college only \n",
    " 'one_year_more_college', # college only \n",
    " \n",
    " # sex/age/schooling - males only\n",
    " 'male_45_64_associates_degree',\n",
    " 'male_45_64_bachelors_degree',\n",
    " 'male_45_64_graduate_degree',\n",
    " 'male_45_64_less_than_9_grade',\n",
    " 'male_45_64_grade_9_12',\n",
    " 'male_45_64_high_school',\n",
    " 'male_45_64_some_college',\n",
    " # male_45_64 (already on 'demograhics')\n",
    " \n",
    " # employment/occupation SECTOR\n",
    " 'employed_agriculture_forestry_fishing_hunting_mining',\n",
    " 'employed_arts_entertainment_recreation_accommodation_food',\n",
    " 'employed_construction',\n",
    " 'employed_education_health_social',\n",
    " 'employed_finance_insurance_real_estate',\n",
    " 'employed_information',\n",
    " 'employed_manufacturing',\n",
    " 'employed_other_services_not_public_admin',\n",
    " 'employed_public_administration',\n",
    " 'employed_retail_trade',\n",
    " 'employed_science_management_admin_waste',\n",
    " 'employed_transportation_warehousing_utilities',\n",
    " 'employed_wholesale_trade',\n",
    " \n",
    " 'occupation_management_arts',\n",
    " 'occupation_natural_resources_construction_maintenance',\n",
    " 'occupation_production_transportation_material',\n",
    " 'occupation_sales_office',\n",
    " 'occupation_services',\n",
    " \n",
    " 'management_business_sci_arts_employed',\n",
    " 'sales_office_employed',\n",
    " \n",
    " 'worked_at_home',\n",
    " 'workers_16_and_over',\n",
    " \n",
    " # inequality / poverty\n",
    " 'gini_index',\n",
    " 'households_public_asst_or_food_stamps',\n",
    " 'poverty',\n",
    " 'pop_determined_poverty_status', \n",
    " \n",
    " # marital status\n",
    " 'pop_never_married',\n",
    " 'pop_now_married',\n",
    " 'pop_separated',\n",
    " 'pop_widowed',\n",
    " 'pop_divorced',\n",
    " #'married_households', # added to 'households'\n",
    " \n",
    " # race and race/age            \n",
    " 'white_pop',\n",
    " 'amerindian_pop',\n",
    " 'asian_pop',\n",
    " 'black_pop',\n",
    " 'hispanic_pop', \n",
    " 'other_race_pop',\n",
    " 'not_hispanic_pop',\n",
    " 'two_or_more_races_pop',\n",
    " \n",
    " 'hispanic_any_race',\n",
    " 'amerindian_including_hispanic',\n",
    " 'asian_including_hispanic', \n",
    " 'black_including_hispanic',\n",
    " 'white_including_hispanic',\n",
    "\n",
    " 'asian_male_45_54',\n",
    " 'asian_male_55_64',\n",
    " 'black_male_45_54',\n",
    " 'black_male_55_64', \n",
    " 'hispanic_male_45_54',\n",
    " 'hispanic_male_55_64',\n",
    " 'white_male_45_54',\n",
    " 'white_male_55_64',\n",
    "    \n",
    " 'speak_only_english_at_home',\n",
    " 'speak_spanish_at_home',\n",
    " 'speak_spanish_at_home_low_english',\n",
    "             \n",
    "  # commute/accessibility\n",
    " 'aggregate_travel_time_to_work',\n",
    "\n",
    " 'commute_5_9_mins',\n",
    " 'commute_35_39_mins',\n",
    " 'commute_40_44_mins',\n",
    " 'commute_60_89_mins',\n",
    " 'commute_90_more_mins',\n",
    " \n",
    " 'commute_less_10_mins',\n",
    " 'commute_35_44_mins',\n",
    " 'commute_60_more_mins',\n",
    " \n",
    " 'commuters_by_public_transportation',\n",
    " 'commuters_by_bus',\n",
    " 'commuters_by_car_truck_van',\n",
    " 'commuters_by_carpool',\n",
    " 'commuters_by_subway_or_elevated',\n",
    " 'commuters_drove_alone',\n",
    " 'walked_to_work',\n",
    "             \n",
    " 'commute_10_14_mins',\n",
    " 'commute_15_19_mins',\n",
    " 'commute_20_24_mins',\n",
    " 'commute_25_29_mins',\n",
    " 'commute_30_34_mins',\n",
    " 'commute_45_59_mins',\n",
    " \n",
    " 'commuters_16_over', # commuters not children\n",
    "\n",
    " 'no_car',\n",
    " 'no_cars',\n",
    " 'one_car',\n",
    " 'two_cars',\n",
    " 'three_cars',\n",
    " 'four_more_cars',\n",
    "            \n",
    " #------------------------------------------------------------------------------------------\n",
    "  # housing\n",
    " #------------------------------------------------------------------------------------------\n",
    " 'housing_units',\n",
    " 'million_dollar_housing_units',\n",
    " 'mortgaged_housing_units',\n",
    " 'median_year_structure_built',\n",
    " \n",
    " # housing structure\n",
    " 'dwellings_1_units_detached',\n",
    " 'dwellings_1_units_attached',\n",
    " 'dwellings_2_units',\n",
    " 'dwellings_3_to_4_units',\n",
    " 'dwellings_5_to_9_units',\n",
    " 'dwellings_10_to_19_units',\n",
    " 'dwellings_20_to_49_units',\n",
    " 'dwellings_50_or_more_units',\n",
    " \n",
    " 'housing_built_2005_or_later',\n",
    " 'housing_built_2000_to_2004',\n",
    " 'housing_built_1939_or_earlier',    \n",
    "             \n",
    " # occupancy/vacancy\n",
    " 'occupied_housing_units',\n",
    " 'housing_units_renter_occupied',\n",
    " 'owner_occupied_housing_units',\n",
    " 'owner_occupied_housing_units_lower_value_quartile',\n",
    " 'owner_occupied_housing_units_median_value',\n",
    " 'owner_occupied_housing_units_upper_value_quartile',\n",
    " 'vacant_housing_units',\n",
    " 'vacant_housing_units_for_rent',\n",
    " 'vacant_housing_units_for_sale',\n",
    "\n",
    " #other dwellings         \n",
    " 'group_quarters',  \n",
    " 'mobile_homes',\n",
    " \n",
    " # rental burden\n",
    " 'median_rent',\n",
    " 'percent_income_spent_on_rent',\n",
    " 'rent_10_to_15_percent',\n",
    " 'rent_15_to_20_percent',\n",
    " 'rent_20_to_25_percent',\n",
    " 'rent_25_to_30_percent',\n",
    " 'rent_30_to_35_percent',\n",
    " 'rent_35_to_40_percent',\n",
    " 'rent_40_to_50_percent',\n",
    " 'rent_burden_not_computed',\n",
    "             \n",
    " 'rent_over_50_percent',\n",
    " 'rent_under_10_percent',\n",
    "             \n",
    " 'renter_occupied_housing_units_paying_cash_median_gross_rent',\n",
    "  \n",
    " # movers           \n",
    " 'different_house_year_ago_different_city',\n",
    " 'different_house_year_ago_same_city',\n",
    "           \n",
    " #year\n",
    " 'do_date']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### list chosen variables\n",
    "These are the variables I chose from ACS-1. I will use them either as **covariates** or for **descriptive statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_chosen = [\n",
    "  \n",
    " 'geo_id',   # FIPS\n",
    " 'do_date', # year\n",
    "    \n",
    " ### size/scale\n",
    " 'total_pop', \n",
    "    \n",
    " ### Age structure \n",
    " 'pop_25_years_over',  # subtract from 'pop_25_64' to get elderly\n",
    " 'pop_25_64',          # labour age  \n",
    "  #'median_age',\n",
    "\n",
    " # cosmopolitan county?\n",
    " 'not_us_citizen_pop', # how international\n",
    "    \n",
    " # income distribution: later will bin, cutting on 25k, 50k, 100k\n",
    " 'income_less_10000',\n",
    " 'income_10000_14999',\n",
    " 'income_15000_19999',\n",
    " 'income_20000_24999',\n",
    " 'income_25000_29999',\n",
    " 'income_30000_34999',\n",
    " 'income_35000_39999',\n",
    " 'income_40000_44999',\n",
    " 'income_45000_49999',\n",
    " 'income_50000_59999',\n",
    " 'income_60000_74999',\n",
    " 'income_75000_99999',\n",
    " 'income_100000_124999',\n",
    " 'income_125000_149999',\n",
    " 'income_150000_199999',\n",
    " 'income_200000_or_more',\n",
    "    \n",
    "# employment\n",
    " 'employed_pop',\n",
    " 'employed_arts_entertainment_recreation_accommodation_food',\n",
    " 'employed_finance_insurance_real_estate',\n",
    " 'employed_information',\n",
    " 'employed_public_administration',\n",
    " 'employed_science_management_admin_waste',\n",
    "\n",
    " # schooling\n",
    " 'bachelors_degree_or_higher_25_64',\n",
    "\n",
    " # indicator for central/suburban/residential area\n",
    " 'aggregate_travel_time_to_work',\n",
    "    \n",
    "# movers           \n",
    " 'different_house_year_ago_different_city',\n",
    "\n",
    " # for descriptive statistics\n",
    " 'male_pop',\n",
    " 'female_pop',\n",
    " 'asian_including_hispanic', \n",
    " 'black_including_hispanic',\n",
    " 'white_including_hispanic',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../output/tbl_ACS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>do_date</th>\n",
       "      <th>total_pop</th>\n",
       "      <th>pop_25_years_over</th>\n",
       "      <th>pop_25_64</th>\n",
       "      <th>not_us_citizen_pop</th>\n",
       "      <th>income_less_10000</th>\n",
       "      <th>income_10000_14999</th>\n",
       "      <th>income_15000_19999</th>\n",
       "      <th>income_20000_24999</th>\n",
       "      <th>...</th>\n",
       "      <th>employed_public_administration</th>\n",
       "      <th>employed_science_management_admin_waste</th>\n",
       "      <th>bachelors_degree_or_higher_25_64</th>\n",
       "      <th>aggregate_travel_time_to_work</th>\n",
       "      <th>different_house_year_ago_different_city</th>\n",
       "      <th>male_pop</th>\n",
       "      <th>female_pop</th>\n",
       "      <th>asian_including_hispanic</th>\n",
       "      <th>black_including_hispanic</th>\n",
       "      <th>white_including_hispanic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26055</td>\n",
       "      <td>2011</td>\n",
       "      <td>88349.0</td>\n",
       "      <td>62370.0</td>\n",
       "      <td>49054.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>2099.0</td>\n",
       "      <td>2817.0</td>\n",
       "      <td>2178.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>4066.0</td>\n",
       "      <td>15372.0</td>\n",
       "      <td>853610.0</td>\n",
       "      <td>11227.0</td>\n",
       "      <td>43962.0</td>\n",
       "      <td>44387.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>83703.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37035</td>\n",
       "      <td>2011</td>\n",
       "      <td>154181.0</td>\n",
       "      <td>104803.0</td>\n",
       "      <td>82218.0</td>\n",
       "      <td>7853.0</td>\n",
       "      <td>3723.0</td>\n",
       "      <td>3563.0</td>\n",
       "      <td>2968.0</td>\n",
       "      <td>4491.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1834.0</td>\n",
       "      <td>4620.0</td>\n",
       "      <td>18739.0</td>\n",
       "      <td>1395380.0</td>\n",
       "      <td>13511.0</td>\n",
       "      <td>75406.0</td>\n",
       "      <td>78775.0</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>13430.0</td>\n",
       "      <td>127753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40131</td>\n",
       "      <td>2011</td>\n",
       "      <td>87706.0</td>\n",
       "      <td>57866.0</td>\n",
       "      <td>45681.0</td>\n",
       "      <td>1086.0</td>\n",
       "      <td>1537.0</td>\n",
       "      <td>1492.0</td>\n",
       "      <td>1347.0</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2047.0</td>\n",
       "      <td>3130.0</td>\n",
       "      <td>12354.0</td>\n",
       "      <td>957410.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43259.0</td>\n",
       "      <td>44447.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>66501.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_id  do_date  total_pop  pop_25_years_over  pop_25_64  \\\n",
       "0   26055     2011    88349.0            62370.0    49054.0   \n",
       "1   37035     2011   154181.0           104803.0    82218.0   \n",
       "2   40131     2011    87706.0            57866.0    45681.0   \n",
       "\n",
       "   not_us_citizen_pop  income_less_10000  income_10000_14999  \\\n",
       "0              1351.0             1521.0              2099.0   \n",
       "1              7853.0             3723.0              3563.0   \n",
       "2              1086.0             1537.0              1492.0   \n",
       "\n",
       "   income_15000_19999  income_20000_24999  ...  \\\n",
       "0              2817.0              2178.0  ...   \n",
       "1              2968.0              4491.0  ...   \n",
       "2              1347.0              1961.0  ...   \n",
       "\n",
       "   employed_public_administration  employed_science_management_admin_waste  \\\n",
       "0                          1155.0                                   4066.0   \n",
       "1                          1834.0                                   4620.0   \n",
       "2                          2047.0                                   3130.0   \n",
       "\n",
       "   bachelors_degree_or_higher_25_64  aggregate_travel_time_to_work  \\\n",
       "0                           15372.0                       853610.0   \n",
       "1                           18739.0                      1395380.0   \n",
       "2                           12354.0                       957410.0   \n",
       "\n",
       "   different_house_year_ago_different_city  male_pop  female_pop  \\\n",
       "0                                  11227.0   43962.0     44387.0   \n",
       "1                                  13511.0   75406.0     78775.0   \n",
       "2                                      NaN   43259.0     44447.0   \n",
       "\n",
       "   asian_including_hispanic  black_including_hispanic  \\\n",
       "0                     565.0                    1976.0   \n",
       "1                    4709.0                   13430.0   \n",
       "2                    1120.0                    1144.0   \n",
       "\n",
       "   white_including_hispanic  \n",
       "0                   83703.0  \n",
       "1                  127753.0  \n",
       "2                   66501.0  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[var_chosen]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "different_house_year_ago_different_city                      26.163579\n",
       "employed_finance_insurance_real_estate                       14.670884\n",
       "employed_science_management_admin_waste                      14.670884\n",
       "employed_arts_entertainment_recreation_accommodation_food    14.670884\n",
       "employed_information                                         14.670884\n",
       "employed_public_administration                               14.670884\n",
       "black_including_hispanic                                      5.061003\n",
       "white_including_hispanic                                      5.061003\n",
       "asian_including_hispanic                                      5.061003\n",
       "not_us_citizen_pop                                            2.364814\n",
       "pop_25_years_over                                             0.346438\n",
       "bachelors_degree_or_higher_25_64                              0.105438\n",
       "aggregate_travel_time_to_work                                 0.105438\n",
       "pop_25_64                                                     0.105438\n",
       "total_pop                                                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % missing for variables with NAs\n",
    "100 * df.isna().sum().sort_values(ascending=False)[:15]/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011    147\n",
       "2017    141\n",
       "2018    139\n",
       "2016    116\n",
       "2013    116\n",
       "2015    110\n",
       "2014    104\n",
       "2012    101\n",
       "Name: do_date, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number missing for a specific variable, per year\n",
    "df.do_date[df.employed_finance_insurance_real_estate.isna()].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite over 14% of NAs for employemnt by sector, the missing data is scattered accross years. I will leave any adjustments for later, after I select only the FIPS needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3  Edit columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1. income - reduce number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['income_less_10000', 'income_10000_14999', 'income_15000_19999',\n",
       "       'income_20000_24999', 'income_25000_29999', 'income_30000_34999',\n",
       "       'income_35000_39999', 'income_40000_44999', 'income_45000_49999',\n",
       "       'income_50000_59999', 'income_60000_74999', 'income_75000_99999',\n",
       "       'income_100000_124999', 'income_125000_149999', 'income_150000_199999',\n",
       "       'income_200000_or_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "income_cols = df.columns[df.columns.str.contains('income')]\n",
    "income_cols "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['df.income_less_10000', 'df.income_10000_14999',\n",
       "       'df.income_15000_19999', 'df.income_20000_24999',\n",
       "       'df.income_25000_29999', 'df.income_30000_34999',\n",
       "       'df.income_35000_39999', 'df.income_40000_44999',\n",
       "       'df.income_45000_49999', 'df.income_50000_59999',\n",
       "       'df.income_60000_74999', 'df.income_75000_99999',\n",
       "       'df.income_100000_124999', 'df.income_125000_149999',\n",
       "       'df.income_150000_199999', 'df.income_200000_or_more'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat 'df.' and use it to copy/paste for condensed categories bellow\n",
    "pd.Series.add_prefix(income_cols.to_series(), 'df.').index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total number of income respondents - sum all income categories for each row\n",
    "income_respondents = df[df.columns[df.columns.str.contains('income')]].sum(axis=1)\n",
    "\n",
    "# condensed categories\n",
    "df['income_less_25k']  = (df.income_less_10000  + \n",
    "                          df.income_10000_14999 + \n",
    "                          df.income_15000_19999 + \n",
    "                          df.income_20000_24999)/income_respondents \n",
    "            \n",
    "df['income_25k_50k']   = (df.income_25000_29999 +\n",
    "                          df.income_30000_34999 +\n",
    "                          df.income_35000_39999 +\n",
    "                          df.income_40000_44999 +\n",
    "                          df.income_45000_49999)/income_respondents \n",
    "            \n",
    "df['income_50k_100k']  = (df.income_50000_59999 +\n",
    "                          df.income_60000_74999 +\n",
    "                          df.income_75000_99999)/income_respondents \n",
    "               \n",
    "df['income_100k_plus'] = (df.income_100000_124999 +\n",
    "                          df.income_125000_149999 +\n",
    "                          df.income_150000_199999 +\n",
    "                          df.income_200000_or_more)/income_respondents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(income_cols,1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.  Age - make '65 plus' column and show percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_pop\n",
    "    \n",
    "### Age structure \n",
    "df['age_65plus'] = (df.pop_25_years_over - df.pop_25_64)/df.total_pop\n",
    "df['age_25_64']= df.pop_25_64/df.total_pop\n",
    "df['bachelors'] = df.bachelors_degree_or_higher_25_64/df.pop_25_64\n",
    "df.drop(['pop_25_years_over','bachelors_degree_or_higher_25_64'],1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.  Employment per sector - percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['employed_arts_entertainment_recreation_accommodation_food',\n",
       " 'employed_finance_insurance_real_estate',\n",
       " 'employed_information',\n",
       " 'employed_public_administration',\n",
       " 'employed_science_management_admin_waste']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employed_cols = df.columns[df.columns.str.contains('employed')].to_list()\n",
    "employed_cols.remove('employed_pop')\n",
    "employed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# percentages - divide all employment columns by total employment\n",
    "df[employed_cols] = df[employed_cols].div(df.employed_pop, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'employed_arts_entertainment_recreation_accommodation_food': 'emp_hospitality',\n",
    "                   'employed_finance_insurance_real_estate': 'emp_finance', \n",
    "                   'employed_information':'emp_information',\n",
    "                   'employed_public_administration':'emp_public_adm',\n",
    "                   'employed_science_management_admin_waste':'emp_science_admin'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3. Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make percentages\n",
    "df.asian_including_hispanic = df.asian_including_hispanic/df.total_pop\n",
    "df.black_including_hispanic = df.black_including_hispanic/df.total_pop\n",
    "df.white_including_hispanic = df.white_including_hispanic/df.total_pop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'asian_including_hispanic': 'asian',\n",
    "                   'black_including_hispanic': 'black', \n",
    "                   'white_including_hispanic':'white',},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4. Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make percentages\n",
    "df.male_pop = df.male_pop/df.total_pop\n",
    "df.female_pop = df.female_pop/df.total_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'male_pop': 'male',\n",
    "                   'female_pop': 'female',},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5. Other columns to percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.not_us_citizen_pop = df.not_us_citizen_pop/df.total_pop\n",
    "df.employed_pop = df.employed_pop/df.pop_25_64\n",
    "# movers           \n",
    "df.different_house_year_ago_different_city = df.different_house_year_ago_different_city/df.total_pop\n",
    "df.drop('pop_25_64',1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'not_us_citizen_pop': 'not_us_citizen',\n",
    "                   'employed_pop': 'employment',\n",
    "                   'aggregate_travel_time_to_work':'commute_time',\n",
    "                   'do_date':'year',\n",
    "                   'total_pop':'population',\n",
    "                   'different_house_year_ago_different_city':'immigration'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. add density and centroid coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>area_land_meters</th>\n",
       "      <th>area_water_meters</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1013</td>\n",
       "      <td>2012002531</td>\n",
       "      <td>2701198</td>\n",
       "      <td>31.751667</td>\n",
       "      <td>-86.681969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1059</td>\n",
       "      <td>1641841404</td>\n",
       "      <td>32643981</td>\n",
       "      <td>34.441989</td>\n",
       "      <td>-87.842814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1041</td>\n",
       "      <td>1576952799</td>\n",
       "      <td>5388562</td>\n",
       "      <td>31.732826</td>\n",
       "      <td>-86.319222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_id  area_land_meters  area_water_meters  centroid_lat  centroid_lon\n",
       "0    1013        2012002531            2701198     31.751667    -86.681969\n",
       "1    1059        1641841404           32643981     34.441989    -87.842814\n",
       "2    1041        1576952799            5388562     31.732826    -86.319222"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_area = pd.read_csv('../input2/UScounty_boundaries.csv', index_col=0)\n",
    "\n",
    "df_area.rename(columns={'int_point_lat':'centroid_lat', \n",
    "                   'int_point_lon':'centroid_lon',},inplace=True)\n",
    "df_area.head(3)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_area.drop('area_water_meters',1), how='left', on='geo_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['density'] = df.population/df.area_land_meters\n",
    "df.drop('area_land_meters',1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Normalize remaining variables to  [0,1] range\n",
    "Later, once we chose FIPS for analysis, I will normalize `Population`, `commute time` and `density` to [0,1], so units are similar to the other variables,  keeping originals (not normalized) for robustness check. I willleave code bellow for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxmin_scale(s, smax=0, smin=1):\n",
    "    s_std = (s - s.min()) / (s.max() - s.min())\n",
    "    s = s_std * (smax - smin) + smin\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['population_norm'] = maxmin_scale(df.population)\n",
    "df['commute_norm'] = maxmin_scale(df.commute_time)\n",
    "df['density_norm'] = maxmin_scale(df.density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. save\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save local -  Name 'ready' for ready to use!\n",
    "df.to_csv('../output/tbl_ACS_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>not_us_citizen</th>\n",
       "      <th>employment</th>\n",
       "      <th>emp_hospitality</th>\n",
       "      <th>emp_finance</th>\n",
       "      <th>emp_information</th>\n",
       "      <th>emp_public_adm</th>\n",
       "      <th>emp_science_admin</th>\n",
       "      <th>...</th>\n",
       "      <th>income_100k_plus</th>\n",
       "      <th>age_65plus</th>\n",
       "      <th>age_25_64</th>\n",
       "      <th>bachelors</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "      <th>density</th>\n",
       "      <th>population_norm</th>\n",
       "      <th>commute_norm</th>\n",
       "      <th>density_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26055</td>\n",
       "      <td>2011</td>\n",
       "      <td>88349.0</td>\n",
       "      <td>0.015292</td>\n",
       "      <td>0.853651</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>0.080573</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.027582</td>\n",
       "      <td>0.097099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.191084</td>\n",
       "      <td>0.150720</td>\n",
       "      <td>0.555230</td>\n",
       "      <td>0.313369</td>\n",
       "      <td>44.718688</td>\n",
       "      <td>-85.553848</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.997373</td>\n",
       "      <td>0.996420</td>\n",
       "      <td>0.997461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37035</td>\n",
       "      <td>2011</td>\n",
       "      <td>154181.0</td>\n",
       "      <td>0.050934</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.077970</td>\n",
       "      <td>0.042074</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.026981</td>\n",
       "      <td>0.067966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143567</td>\n",
       "      <td>0.146484</td>\n",
       "      <td>0.533256</td>\n",
       "      <td>0.227918</td>\n",
       "      <td>35.661883</td>\n",
       "      <td>-81.214906</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.990860</td>\n",
       "      <td>0.992758</td>\n",
       "      <td>0.994821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40131</td>\n",
       "      <td>2011</td>\n",
       "      <td>87706.0</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>0.880322</td>\n",
       "      <td>0.053812</td>\n",
       "      <td>0.047421</td>\n",
       "      <td>0.016089</td>\n",
       "      <td>0.050903</td>\n",
       "      <td>0.077834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206178</td>\n",
       "      <td>0.138930</td>\n",
       "      <td>0.520842</td>\n",
       "      <td>0.270441</td>\n",
       "      <td>36.377794</td>\n",
       "      <td>-95.601383</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.995719</td>\n",
       "      <td>0.998284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41071</td>\n",
       "      <td>2011</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.052270</td>\n",
       "      <td>0.897886</td>\n",
       "      <td>0.100885</td>\n",
       "      <td>0.050126</td>\n",
       "      <td>0.007980</td>\n",
       "      <td>0.058216</td>\n",
       "      <td>0.094083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172165</td>\n",
       "      <td>0.137090</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>0.198434</td>\n",
       "      <td>45.247827</td>\n",
       "      <td>-123.316399</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.996220</td>\n",
       "      <td>0.995380</td>\n",
       "      <td>0.998149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36091</td>\n",
       "      <td>2011</td>\n",
       "      <td>220882.0</td>\n",
       "      <td>0.021699</td>\n",
       "      <td>0.911223</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>0.085073</td>\n",
       "      <td>0.022258</td>\n",
       "      <td>0.078181</td>\n",
       "      <td>0.102075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279563</td>\n",
       "      <td>0.138984</td>\n",
       "      <td>0.555808</td>\n",
       "      <td>0.421266</td>\n",
       "      <td>43.106135</td>\n",
       "      <td>-73.855387</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.984262</td>\n",
       "      <td>0.984308</td>\n",
       "      <td>0.996338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_id  year  population  not_us_citizen  employment  emp_hospitality  \\\n",
       "0   26055  2011     88349.0        0.015292    0.853651         0.116943   \n",
       "1   37035  2011    154181.0        0.050934    0.826765         0.077970   \n",
       "2   40131  2011     87706.0        0.012382    0.880322         0.053812   \n",
       "3   41071  2011    100000.0        0.052270    0.897886         0.100885   \n",
       "4   36091  2011    220882.0        0.021699    0.911223         0.085904   \n",
       "\n",
       "   emp_finance  emp_information  emp_public_adm  emp_science_admin  ...  \\\n",
       "0     0.080573         0.021994        0.027582           0.097099  ...   \n",
       "1     0.042074         0.013240        0.026981           0.067966  ...   \n",
       "2     0.047421         0.016089        0.050903           0.077834  ...   \n",
       "3     0.050126         0.007980        0.058216           0.094083  ...   \n",
       "4     0.085073         0.022258        0.078181           0.102075  ...   \n",
       "\n",
       "   income_100k_plus  age_65plus  age_25_64  bachelors  centroid_lat  \\\n",
       "0          0.191084    0.150720   0.555230   0.313369     44.718688   \n",
       "1          0.143567    0.146484   0.533256   0.227918     35.661883   \n",
       "2          0.206178    0.138930   0.520842   0.270441     36.377794   \n",
       "3          0.172165    0.137090   0.510800   0.198434     45.247827   \n",
       "4          0.279563    0.138984   0.555808   0.421266     43.106135   \n",
       "\n",
       "   centroid_lon   density  population_norm  commute_norm  density_norm  \n",
       "0    -85.553848  0.000073         0.997373      0.996420      0.997461  \n",
       "1    -81.214906  0.000148         0.990860      0.992758      0.994821  \n",
       "2    -95.601383  0.000050         0.997436      0.995719      0.998284  \n",
       "3   -123.316399  0.000054         0.996220      0.995380      0.998149  \n",
       "4    -73.855387  0.000105         0.984262      0.984308      0.996338  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test reading it\n",
    "f = pd.read_csv('../output/tbl_ACS_ready.csv')\n",
    "f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_id</th>\n",
       "      <th>year</th>\n",
       "      <th>population</th>\n",
       "      <th>not_us_citizen</th>\n",
       "      <th>employment</th>\n",
       "      <th>emp_hospitality</th>\n",
       "      <th>emp_finance</th>\n",
       "      <th>emp_information</th>\n",
       "      <th>emp_public_adm</th>\n",
       "      <th>emp_science_admin</th>\n",
       "      <th>...</th>\n",
       "      <th>income_100k_plus</th>\n",
       "      <th>age_65plus</th>\n",
       "      <th>age_25_64</th>\n",
       "      <th>bachelors</th>\n",
       "      <th>centroid_lat</th>\n",
       "      <th>centroid_lon</th>\n",
       "      <th>density</th>\n",
       "      <th>population_norm</th>\n",
       "      <th>commute_norm</th>\n",
       "      <th>density_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6.639000e+03</td>\n",
       "      <td>6482.000000</td>\n",
       "      <td>6632.000000</td>\n",
       "      <td>5665.000000</td>\n",
       "      <td>5665.000000</td>\n",
       "      <td>5665.000000</td>\n",
       "      <td>5665.000000</td>\n",
       "      <td>5665.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6611.000000</td>\n",
       "      <td>6632.000000</td>\n",
       "      <td>6632.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "      <td>6632.000000</td>\n",
       "      <td>6639.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>30534.095647</td>\n",
       "      <td>2014.513782</td>\n",
       "      <td>3.276236e+05</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.889347</td>\n",
       "      <td>0.096121</td>\n",
       "      <td>0.060532</td>\n",
       "      <td>0.018180</td>\n",
       "      <td>0.050512</td>\n",
       "      <td>0.100119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.225644</td>\n",
       "      <td>0.152573</td>\n",
       "      <td>0.516849</td>\n",
       "      <td>0.295786</td>\n",
       "      <td>37.776895</td>\n",
       "      <td>-89.510628</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.973702</td>\n",
       "      <td>0.975928</td>\n",
       "      <td>0.988169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16178.101571</td>\n",
       "      <td>2.291912</td>\n",
       "      <td>5.774915e+05</td>\n",
       "      <td>0.039731</td>\n",
       "      <td>0.097308</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>0.022470</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.033982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100351</td>\n",
       "      <td>0.041362</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>5.618361</td>\n",
       "      <td>15.119939</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.057129</td>\n",
       "      <td>0.052816</td>\n",
       "      <td>0.046494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1003.000000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>6.179200e+04</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.481008</td>\n",
       "      <td>0.028177</td>\n",
       "      <td>0.009004</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.023703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009595</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>0.313760</td>\n",
       "      <td>0.067995</td>\n",
       "      <td>18.001717</td>\n",
       "      <td>-159.705965</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17115.000000</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>9.472600e+04</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.830893</td>\n",
       "      <td>0.079731</td>\n",
       "      <td>0.044896</td>\n",
       "      <td>0.012760</td>\n",
       "      <td>0.032372</td>\n",
       "      <td>0.076653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.126189</td>\n",
       "      <td>0.502165</td>\n",
       "      <td>0.214281</td>\n",
       "      <td>34.277239</td>\n",
       "      <td>-94.888456</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.974074</td>\n",
       "      <td>0.978142</td>\n",
       "      <td>0.992082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34007.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.558100e+05</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.893188</td>\n",
       "      <td>0.092042</td>\n",
       "      <td>0.057374</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.042009</td>\n",
       "      <td>0.095110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203315</td>\n",
       "      <td>0.148584</td>\n",
       "      <td>0.520562</td>\n",
       "      <td>0.281161</td>\n",
       "      <td>38.827120</td>\n",
       "      <td>-85.353048</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.990699</td>\n",
       "      <td>0.991240</td>\n",
       "      <td>0.996369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42095.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.238610e+05</td>\n",
       "      <td>0.056642</td>\n",
       "      <td>0.945926</td>\n",
       "      <td>0.106857</td>\n",
       "      <td>0.072318</td>\n",
       "      <td>0.022139</td>\n",
       "      <td>0.060183</td>\n",
       "      <td>0.118011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276602</td>\n",
       "      <td>0.171286</td>\n",
       "      <td>0.535078</td>\n",
       "      <td>0.356591</td>\n",
       "      <td>41.549013</td>\n",
       "      <td>-79.640119</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.996742</td>\n",
       "      <td>0.995943</td>\n",
       "      <td>0.998158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72139.000000</td>\n",
       "      <td>2018.000000</td>\n",
       "      <td>1.017029e+07</td>\n",
       "      <td>0.254530</td>\n",
       "      <td>1.354425</td>\n",
       "      <td>0.319878</td>\n",
       "      <td>0.237129</td>\n",
       "      <td>0.066441</td>\n",
       "      <td>0.220409</td>\n",
       "      <td>0.318250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662944</td>\n",
       "      <td>0.568169</td>\n",
       "      <td>0.669270</td>\n",
       "      <td>0.787130</td>\n",
       "      <td>64.676044</td>\n",
       "      <td>-65.968778</td>\n",
       "      <td>0.028365</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             geo_id         year    population  not_us_citizen   employment  \\\n",
       "count   6639.000000  6639.000000  6.639000e+03     6482.000000  6632.000000   \n",
       "mean   30534.095647  2014.513782  3.276236e+05        0.044343     0.889347   \n",
       "std    16178.101571     2.291912  5.774915e+05        0.039731     0.097308   \n",
       "min     1003.000000  2011.000000  6.179200e+04        0.000201     0.481008   \n",
       "25%    17115.000000  2013.000000  9.472600e+04        0.017293     0.830893   \n",
       "50%    34007.000000  2015.000000  1.558100e+05        0.031718     0.893188   \n",
       "75%    42095.000000  2017.000000  3.238610e+05        0.056642     0.945926   \n",
       "max    72139.000000  2018.000000  1.017029e+07        0.254530     1.354425   \n",
       "\n",
       "       emp_hospitality  emp_finance  emp_information  emp_public_adm  \\\n",
       "count      5665.000000  5665.000000      5665.000000     5665.000000   \n",
       "mean          0.096121     0.060532         0.018180        0.050512   \n",
       "std           0.027483     0.022470         0.008187        0.028269   \n",
       "min           0.028177     0.009004         0.001197        0.005537   \n",
       "25%           0.079731     0.044896         0.012760        0.032372   \n",
       "50%           0.092042     0.057374         0.016966        0.042009   \n",
       "75%           0.106857     0.072318         0.022139        0.060183   \n",
       "max           0.319878     0.237129         0.066441        0.220409   \n",
       "\n",
       "       emp_science_admin  ...  income_100k_plus   age_65plus    age_25_64  \\\n",
       "count        5665.000000  ...       6639.000000  6611.000000  6632.000000   \n",
       "mean            0.100119  ...          0.225644     0.152573     0.516849   \n",
       "std             0.033982  ...          0.100351     0.041362     0.029954   \n",
       "min             0.023703  ...          0.009595     0.062596     0.313760   \n",
       "25%             0.076653  ...          0.153921     0.126189     0.502165   \n",
       "50%             0.095110  ...          0.203315     0.148584     0.520562   \n",
       "75%             0.118011  ...          0.276602     0.171286     0.535078   \n",
       "max             0.318250  ...          0.662944     0.568169     0.669270   \n",
       "\n",
       "         bachelors  centroid_lat  centroid_lon      density  population_norm  \\\n",
       "count  6632.000000   6639.000000   6639.000000  6639.000000      6639.000000   \n",
       "mean      0.295786     37.776895    -89.510628     0.000337         0.973702   \n",
       "std       0.109421      5.618361     15.119939     0.001319         0.057129   \n",
       "min       0.067995     18.001717   -159.705965     0.000001         0.000000   \n",
       "25%       0.214281     34.277239    -94.888456     0.000054         0.974074   \n",
       "50%       0.281161     38.827120    -85.353048     0.000104         0.990699   \n",
       "75%       0.356591     41.549013    -79.640119     0.000226         0.996742   \n",
       "max       0.787130     64.676044    -65.968778     0.028365         1.000000   \n",
       "\n",
       "       commute_norm  density_norm  \n",
       "count   6632.000000   6639.000000  \n",
       "mean       0.975928      0.988169  \n",
       "std        0.052816      0.046494  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.978142      0.992082  \n",
       "50%        0.991240      0.996369  \n",
       "75%        0.995943      0.998158  \n",
       "max        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "## 2. Air quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%ls ../input2/airquality*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input2/airquality_2019.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add FIPS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_FIPS(df):\n",
    "    \n",
    "    '''adds FIPS columns  to dataframe'''\n",
    "    \n",
    "    # new column with fips codes\n",
    "    fips_S = [str(code).zfill(2) for code in df['state_code']]\n",
    "    fips_C = [str(code1).zfill(3) for code1 in df['county_code']] \n",
    "    loc = df.columns.get_loc('county_code')\n",
    "    df.insert(loc=loc, column='FIPS', value=[S+C for S,C in zip(fips_S, fips_C)]) \n",
    "    df.drop(['state_code','county_code'],1, inplace=True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_FIPS(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Variables available\n",
    "Now I explore the variables from `airquality` dataset, in order to chose some to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### number of variables and counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'variables: {len(df.parameter_name.unique())}')\n",
    "print(f'counties: {len(df.FIPS.unique())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# function to list variables containing a specific string\n",
    "def check_variables(string):\n",
    "    data = df.parameter_name[df.parameter_name.str.contains(string)].unique()\n",
    "    return pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_variables('emperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_variables('ind')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### carbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_variables('arbon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_variables('article')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# used code bellow to copy/paste variables to manually edit\n",
    "\n",
    "#variables=[]\n",
    "#for string in ['emperature', 'arbon', 'artic']:\n",
    "#    variables.extend(list(df.parameter_name[df.parameter_name.str.contains(string)].unique()))\n",
    "#variables    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ['Outdoor Temperature',\n",
    "     'Temperature Difference',\n",
    "     'Indoor Temperature',\n",
    "     'Average Ambient Temperature',\n",
    "     'Ambient Max Temperature',\n",
    "     'Ambient Min Temperature',\n",
    "     'Carbon monoxide',\n",
    "     'Carbon dioxide',\n",
    "     'Total hydrocarbons',\n",
    "     'Suspended particulate (TSP)',\n",
    "     'Solar radiation',   # function of latitude, pollution and weather conditions\n",
    "     'Wind Speed - Resultant',\n",
    "     'Relative Humidity ',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
